{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add dropout compared to simple cnn\n",
    "\n",
    "dropout is added after conv & relu with p=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Subset, DataLoader, ConcatDataset\n",
    "from mouse_model.data_utils_new import MouseDatasetSegNewBehav\n",
    "import numpy as np\n",
    "from mouse_model.evaluation import cor_in_time\n",
    "import random, os\n",
    "from kornia.geometry.transform import get_affine_matrix2d, warp_affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shifter(nn.Module):\n",
    "    def __init__(self, input_dim=4, output_dim=3, hidden_dim=256):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_dim),\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.bias = nn.Parameter(torch.zeros(3))\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1,self.input_dim )\n",
    "        x = self.layers(x)\n",
    "        x0 = (x[...,0] + self.bias[0]) * 80/4\n",
    "        x1 = (x[...,1] + self.bias[1]) * 60/4\n",
    "        x2 = (x[...,2] + self.bias[2]) * 180/4\n",
    "        x = torch.stack([x0, x1, x2], dim=-1)\n",
    "        x = x.reshape(-1,1,self.output_dim)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful for printing in nn.Sequential\n",
    "class PrintLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(PrintLayer, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        return x\n",
    "\n",
    "def size_helper(in_length, kernel_size, padding=0, dilation=1, stride=1):\n",
    "    # https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d\n",
    "    res = in_length + 2 * padding - dilation * (kernel_size - 1) - 1\n",
    "    res /= stride\n",
    "    res += 1\n",
    "    return np.floor(res)\n",
    "\n",
    "# CNN, the last fully connected layer maps to output_dim\n",
    "class VisualEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, output_dim, input_shape=(60, 80), k1=7, k2=7, k3=7):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_shape = (60, 80)\n",
    "        out_shape_0 = size_helper(in_length=input_shape[0], kernel_size=k1, stride=2)\n",
    "        out_shape_0 = size_helper(in_length=out_shape_0, kernel_size=k2, stride=2)\n",
    "        out_shape_0 = size_helper(in_length=out_shape_0, kernel_size=k3, stride=2)\n",
    "        out_shape_1 = size_helper(in_length=input_shape[1], kernel_size=k1, stride=2)\n",
    "        out_shape_1 = size_helper(in_length=out_shape_1, kernel_size=k2, stride=2)\n",
    "        out_shape_1 = size_helper(in_length=out_shape_1, kernel_size=k3, stride=2)\n",
    "        self.output_shape = (int(out_shape_0), int(out_shape_1)) # shape of the final feature map\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=128, kernel_size=k1, stride=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Conv2d(in_channels=128, out_channels=64, kernel_size=k2, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=k3, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.output_shape[0]*self.output_shape[1]*32, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.layers(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predictor(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_neurons):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = VisualEncoder(output_dim=num_neurons)\n",
    "        self.softplus = nn.Softplus()\n",
    "        self.shifter = Shifter()\n",
    "\n",
    "    def forward(self, images, behav):\n",
    "        # print(images.shape)  torch.Size([256, 1, 60, 80])\n",
    "        if args.shifter:\n",
    "            bs = images.size()[0]\n",
    "            behav_shifter = torch.concat((behav[...,4].unsqueeze(-1),   # theta\n",
    "                                          behav[...,3].unsqueeze(-1),   # phi\n",
    "                                          behav[...,1].unsqueeze(-1),  # pitch\n",
    "                                         behav[...,2].unsqueeze(-1),  # roll\n",
    "                                         ), dim=-1)  \n",
    "            shift_param = self.shifter(behav_shifter)  \n",
    "            shift_param = shift_param.reshape(-1,3)\n",
    "            scale_param = torch.ones_like(shift_param[..., 0:2]).to(shift_param.device)\n",
    "            affine_mat = get_affine_matrix2d(\n",
    "                                            translations=shift_param[..., 0:2] ,\n",
    "                                             scale = scale_param, \n",
    "                                             center =torch.repeat_interleave(torch.tensor([[30,40]], dtype=torch.float), \n",
    "                                                                            bs*1, dim=0).to(shift_param.device), \n",
    "                                             angle=shift_param[..., 2])\n",
    "            affine_mat = affine_mat[:, :2, :]\n",
    "            images = warp_affine(images, affine_mat, dsize=(60,80))\n",
    "        pred = self.encoder(images)\n",
    "        pred = self.softplus(pred)\n",
    "        \n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    \n",
    "    seed = 0\n",
    "    file_id = \"070921_J553RT\"\n",
    "    epochs = 100\n",
    "    batch_size = 256\n",
    "    seq_len = 1\n",
    "    num_neurons = 66\n",
    "    learning_rate = 0.0001\n",
    "    segment_num = None\n",
    "    best_train_path = None\n",
    "    best_val_path = None\n",
    "    vid_type = None\n",
    "    shifter = False\n",
    "    \n",
    "args=Args()\n",
    "\n",
    "seed = args.seed\n",
    "random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_val_ds():\n",
    "    ds_list = [MouseDatasetSegNewBehav(file_id=args.file_id, segment_num=args.segment_num, seg_idx=i, data_split=\"train\", \n",
    "                               vid_type=args.vid_type, seq_len=args.seq_len, predict_offset=1) \n",
    "               for i in range(args.segment_num)]\n",
    "    train_ds, val_ds = [], []\n",
    "    for ds in ds_list:\n",
    "        train_ratio = 0.8\n",
    "        train_ds_len = int(len(ds) * train_ratio)\n",
    "        train_ds.append(Subset(ds, np.arange(0, train_ds_len, 1)))\n",
    "        val_ds.append(Subset(ds, np.arange(train_ds_len, len(ds), 1)))\n",
    "    train_ds = ConcatDataset(train_ds)\n",
    "    val_ds = ConcatDataset(val_ds)\n",
    "    print(len(train_ds), len(val_ds))\n",
    "    return train_ds, val_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_ds():\n",
    "    test_ds = [MouseDatasetSegNewBehav(file_id=args.file_id, segment_num=args.segment_num, seg_idx=i, data_split=\"test\", \n",
    "                               vid_type=args.vid_type, seq_len=args.seq_len, predict_offset=1) \n",
    "               for i in range(args.segment_num)]\n",
    "    test_ds = ConcatDataset(test_ds)\n",
    "    return test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    \n",
    "    torch.manual_seed(args.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "    \n",
    "    train_ds, val_ds = load_train_val_ds()\n",
    "\n",
    "    train_dataloader = DataLoader(dataset=train_ds, batch_size=args.batch_size, shuffle=True, num_workers=8)\n",
    "    val_dataloader = DataLoader(dataset=val_ds, batch_size=args.batch_size, shuffle=False, num_workers=8)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "\n",
    "    best_train_loss = np.inf\n",
    "    best_val_loss = np.inf\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    ct = 0\n",
    "\n",
    "    # start training\n",
    "    for epoch in range(args.epochs):\n",
    "\n",
    "        print(\"Start epoch\", epoch)\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        epoch_train_loss = 0\n",
    "\n",
    "        for (image, behav, spikes) in train_dataloader:\n",
    "\n",
    "            image, behav, spikes = image.to(device), behav.to(device), spikes.to(device)\n",
    "            image = torch.squeeze(image, axis=1)\n",
    "\n",
    "            pred = model(image, behav)\n",
    "            \n",
    "            loss = nn.functional.poisson_nll_loss(pred, spikes, reduction='mean', log_input=False)\n",
    "\n",
    "            epoch_train_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_train_loss = epoch_train_loss / len(train_dataloader)\n",
    "\n",
    "        train_loss_list.append(epoch_train_loss)\n",
    "\n",
    "        if epoch_train_loss < best_train_loss:\n",
    "            \n",
    "\n",
    "            torch.save(model.state_dict(), args.best_train_path)\n",
    "            best_train_loss = epoch_train_loss\n",
    "\n",
    "        print(\"Epoch {} train loss: {}\".format(epoch, epoch_train_loss))\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        epoch_val_loss = 0\n",
    "\n",
    "        with torch.no_grad():      \n",
    "\n",
    "            for (image, behav, spikes) in val_dataloader:\n",
    "\n",
    "                image, behav, spikes = image.to(device), behav.to(device), spikes.to(device)\n",
    "                image = torch.squeeze(image, axis=1)\n",
    "\n",
    "                pred = model(image, behav)\n",
    "\n",
    "                loss = nn.functional.poisson_nll_loss(pred, spikes, reduction='mean', log_input=False)\n",
    "\n",
    "                epoch_val_loss += loss.item()\n",
    "\n",
    "        epoch_val_loss = epoch_val_loss / len(val_dataloader)\n",
    "\n",
    "        val_loss_list.append(epoch_val_loss)\n",
    "\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "\n",
    "            torch.save(model.state_dict(), args.best_val_path)\n",
    "            best_val_loss = epoch_val_loss\n",
    "            ct = 0\n",
    "        else: \n",
    "            ct += 1\n",
    "            if ct > 5:\n",
    "                print('stop training')\n",
    "                break\n",
    "\n",
    "        print(\"Epoch {} val loss: {}\".format(epoch, epoch_val_loss))\n",
    "\n",
    "        print(\"End epoch\", epoch)\n",
    "        \n",
    "    return train_loss_list, val_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 vid_mean\n",
      "070921_J553RT\n",
      "30120 7540\n",
      "Start epoch 0\n",
      "Epoch 0 train loss: 0.747644818435281\n",
      "Epoch 0 val loss: 0.6736699104309082\n",
      "End epoch 0\n",
      "Start epoch 1\n",
      "Epoch 1 train loss: 0.6746346632302818\n",
      "Epoch 1 val loss: 0.6592587014039357\n",
      "End epoch 1\n",
      "Start epoch 2\n",
      "Epoch 2 train loss: 0.6611649889056965\n",
      "Epoch 2 val loss: 0.6518249968687694\n",
      "End epoch 2\n",
      "Start epoch 3\n",
      "Epoch 3 train loss: 0.6520782350483587\n",
      "Epoch 3 val loss: 0.6460846602916718\n",
      "End epoch 3\n",
      "Start epoch 4\n",
      "Epoch 4 train loss: 0.6451908057018861\n",
      "Epoch 4 val loss: 0.6414766351381938\n",
      "End epoch 4\n",
      "Start epoch 5\n",
      "Epoch 5 train loss: 0.6399538951405024\n",
      "Epoch 5 val loss: 0.6395488758881887\n",
      "End epoch 5\n",
      "Start epoch 6\n",
      "Epoch 6 train loss: 0.6359735949564789\n",
      "Epoch 6 val loss: 0.6368852873643239\n",
      "End epoch 6\n",
      "Start epoch 7\n",
      "Epoch 7 train loss: 0.6326401905488159\n",
      "Epoch 7 val loss: 0.6359025816122691\n",
      "End epoch 7\n",
      "Start epoch 8\n",
      "Epoch 8 train loss: 0.6300572081137512\n",
      "Epoch 8 val loss: 0.6340619146823883\n",
      "End epoch 8\n",
      "Start epoch 9\n",
      "Epoch 9 train loss: 0.6276526203600027\n",
      "Epoch 9 val loss: 0.6326073050498963\n",
      "End epoch 9\n",
      "Start epoch 10\n",
      "Epoch 10 train loss: 0.6256832253124754\n",
      "Epoch 10 val loss: 0.6323808332284292\n",
      "End epoch 10\n",
      "Start epoch 11\n",
      "Epoch 11 train loss: 0.6239054157572278\n",
      "Epoch 11 val loss: 0.6309695323308309\n",
      "End epoch 11\n",
      "Start epoch 12\n",
      "Epoch 12 train loss: 0.6223582342519598\n",
      "Epoch 12 val loss: 0.6309241354465485\n",
      "End epoch 12\n",
      "Start epoch 13\n",
      "Epoch 13 train loss: 0.6210026629900528\n",
      "Epoch 13 val loss: 0.6290540039539337\n",
      "End epoch 13\n",
      "Start epoch 14\n",
      "Epoch 14 train loss: 0.6197376837164669\n",
      "Epoch 14 val loss: 0.6291061699390411\n",
      "End epoch 14\n",
      "Start epoch 15\n",
      "Epoch 15 train loss: 0.6188642291699425\n",
      "Epoch 15 val loss: 0.6274574021498363\n",
      "End epoch 15\n",
      "Start epoch 16\n",
      "Epoch 16 train loss: 0.6176988063222271\n",
      "Epoch 16 val loss: 0.6267382005850474\n",
      "End epoch 16\n",
      "Start epoch 17\n",
      "Epoch 17 train loss: 0.6166755314600669\n",
      "Epoch 17 val loss: 0.6279566764831543\n",
      "End epoch 17\n",
      "Start epoch 18\n",
      "Epoch 18 train loss: 0.6155457062236334\n",
      "Epoch 18 val loss: 0.6264237403869629\n",
      "End epoch 18\n",
      "Start epoch 19\n",
      "Epoch 19 train loss: 0.6146055677179563\n",
      "Epoch 19 val loss: 0.6260358055432638\n",
      "End epoch 19\n",
      "Start epoch 20\n",
      "Epoch 20 train loss: 0.6141093853166548\n",
      "Epoch 20 val loss: 0.6266257027784984\n",
      "End epoch 20\n",
      "Start epoch 21\n",
      "Epoch 21 train loss: 0.613370582208795\n",
      "Epoch 21 val loss: 0.6251287996768952\n",
      "End epoch 21\n",
      "Start epoch 22\n",
      "Epoch 22 train loss: 0.6123547185275514\n",
      "Epoch 22 val loss: 0.6260063846906027\n",
      "End epoch 22\n",
      "Start epoch 23\n",
      "Epoch 23 train loss: 0.6119271148059328\n",
      "Epoch 23 val loss: 0.6264716148376465\n",
      "End epoch 23\n",
      "Start epoch 24\n",
      "Epoch 24 train loss: 0.6113372616848703\n",
      "Epoch 24 val loss: 0.6240532100200653\n",
      "End epoch 24\n",
      "Start epoch 25\n",
      "Epoch 25 train loss: 0.6107847448122703\n",
      "Epoch 25 val loss: 0.623572454849879\n",
      "End epoch 25\n",
      "Start epoch 26\n",
      "Epoch 26 train loss: 0.6099352609303038\n",
      "Epoch 26 val loss: 0.6239691098531087\n",
      "End epoch 26\n",
      "Start epoch 27\n",
      "Epoch 27 train loss: 0.609748568575261\n",
      "Epoch 27 val loss: 0.6232139925161998\n",
      "End epoch 27\n",
      "Start epoch 28\n",
      "Epoch 28 train loss: 0.6091035735809197\n",
      "Epoch 28 val loss: 0.6229024847348531\n",
      "End epoch 28\n",
      "Start epoch 29\n",
      "Epoch 29 train loss: 0.6086429488860955\n",
      "Epoch 29 val loss: 0.6239177842934926\n",
      "End epoch 29\n",
      "Start epoch 30\n",
      "Epoch 30 train loss: 0.6079604807546584\n",
      "Epoch 30 val loss: 0.6231577277183533\n",
      "End epoch 30\n",
      "Start epoch 31\n",
      "Epoch 31 train loss: 0.6076249404478882\n",
      "Epoch 31 val loss: 0.6255782763163249\n",
      "End epoch 31\n",
      "Start epoch 32\n",
      "Epoch 32 train loss: 0.607202550617315\n",
      "Epoch 32 val loss: 0.6224586844444275\n",
      "End epoch 32\n",
      "Start epoch 33\n",
      "Epoch 33 train loss: 0.6070037554886382\n",
      "Epoch 33 val loss: 0.6237466692924499\n",
      "End epoch 33\n",
      "Start epoch 34\n",
      "Epoch 34 train loss: 0.6065383508043775\n",
      "Epoch 34 val loss: 0.6224184532960256\n",
      "End epoch 34\n",
      "Start epoch 35\n",
      "Epoch 35 train loss: 0.606236504296125\n",
      "Epoch 35 val loss: 0.6240460038185119\n",
      "End epoch 35\n",
      "Start epoch 36\n",
      "Epoch 36 train loss: 0.605820669966229\n",
      "Epoch 36 val loss: 0.6232253630956014\n",
      "End epoch 36\n",
      "Start epoch 37\n",
      "Epoch 37 train loss: 0.6056778173325426\n",
      "Epoch 37 val loss: 0.6239156444867452\n",
      "End epoch 37\n",
      "Start epoch 38\n",
      "Epoch 38 train loss: 0.6051967164217416\n",
      "Epoch 38 val loss: 0.6225022971630096\n",
      "End epoch 38\n",
      "Start epoch 39\n",
      "Epoch 39 train loss: 0.604913429183475\n",
      "Epoch 39 val loss: 0.6217212975025177\n",
      "End epoch 39\n",
      "Start epoch 40\n",
      "Epoch 40 train loss: 0.6046176547721281\n",
      "Epoch 40 val loss: 0.6219439705212911\n",
      "End epoch 40\n",
      "Start epoch 41\n",
      "Epoch 41 train loss: 0.6041778871568583\n",
      "Epoch 41 val loss: 0.6216630617777507\n",
      "End epoch 41\n",
      "Start epoch 42\n",
      "Epoch 42 train loss: 0.603877758575698\n",
      "Epoch 42 val loss: 0.6214217146237692\n",
      "End epoch 42\n",
      "Start epoch 43\n",
      "Epoch 43 train loss: 0.6034486667584564\n",
      "Epoch 43 val loss: 0.6217456380526225\n",
      "End epoch 43\n",
      "Start epoch 44\n",
      "Epoch 44 train loss: 0.6037749713760311\n",
      "Epoch 44 val loss: 0.6214624722798665\n",
      "End epoch 44\n",
      "Start epoch 45\n",
      "Epoch 45 train loss: 0.603172588146339\n",
      "Epoch 45 val loss: 0.6215581317742666\n",
      "End epoch 45\n",
      "Start epoch 46\n",
      "Epoch 46 train loss: 0.6029762575181864\n",
      "Epoch 46 val loss: 0.6229482173919678\n",
      "End epoch 46\n",
      "Start epoch 47\n",
      "Epoch 47 train loss: 0.6026775579331285\n",
      "Epoch 47 val loss: 0.6218655407428741\n",
      "End epoch 47\n",
      "Start epoch 48\n",
      "Epoch 48 train loss: 0.602717516280837\n",
      "stop training\n",
      "10 vid_mean\n",
      "070921_J553RT\n",
      "30120 7540\n",
      "Start epoch 0\n",
      "Epoch 0 train loss: 0.7459188800747112\n",
      "Epoch 0 val loss: 0.6713324407736461\n",
      "End epoch 0\n",
      "Start epoch 1\n",
      "Epoch 1 train loss: 0.6739576989311283\n",
      "Epoch 1 val loss: 0.6568174342314402\n",
      "End epoch 1\n",
      "Start epoch 2\n",
      "Epoch 2 train loss: 0.6606486990290173\n",
      "Epoch 2 val loss: 0.650025067726771\n",
      "End epoch 2\n",
      "Start epoch 3\n",
      "Epoch 3 train loss: 0.651903524237164\n",
      "Epoch 3 val loss: 0.6448610146840413\n",
      "End epoch 3\n",
      "Start epoch 4\n",
      "Epoch 4 train loss: 0.6449524931988474\n",
      "Epoch 4 val loss: 0.6406826396783193\n",
      "End epoch 4\n",
      "Start epoch 5\n",
      "Epoch 5 train loss: 0.6396376702745082\n",
      "Epoch 5 val loss: 0.6376722713311513\n",
      "End epoch 5\n",
      "Start epoch 6\n",
      "Epoch 6 train loss: 0.6350900444944027\n",
      "Epoch 6 val loss: 0.6350102742513021\n",
      "End epoch 6\n",
      "Start epoch 7\n",
      "Epoch 7 train loss: 0.6316444702067617\n",
      "Epoch 7 val loss: 0.6315410772959391\n",
      "End epoch 7\n",
      "Start epoch 8\n",
      "Epoch 8 train loss: 0.6293215488983412\n",
      "Epoch 8 val loss: 0.630688480536143\n",
      "End epoch 8\n",
      "Start epoch 9\n",
      "Epoch 9 train loss: 0.6265595368409561\n",
      "Epoch 9 val loss: 0.6306212067604064\n",
      "End epoch 9\n",
      "Start epoch 10\n",
      "Epoch 10 train loss: 0.6247241694038197\n",
      "Epoch 10 val loss: 0.6279484728972117\n",
      "End epoch 10\n",
      "Start epoch 11\n",
      "Epoch 11 train loss: 0.622670712612443\n",
      "Epoch 11 val loss: 0.6264602601528168\n",
      "End epoch 11\n",
      "Start epoch 12\n",
      "Epoch 12 train loss: 0.6211754563501326\n",
      "Epoch 12 val loss: 0.6268674592177074\n",
      "End epoch 12\n",
      "Start epoch 13\n",
      "Epoch 13 train loss: 0.6194482491178027\n",
      "Epoch 13 val loss: 0.6258689999580384\n",
      "End epoch 13\n",
      "Start epoch 14\n",
      "Epoch 14 train loss: 0.6177603647870532\n",
      "Epoch 14 val loss: 0.6233100990454356\n",
      "End epoch 14\n",
      "Start epoch 15\n",
      "Epoch 15 train loss: 0.6168667416451341\n",
      "Epoch 15 val loss: 0.6229263544082642\n",
      "End epoch 15\n",
      "Start epoch 16\n",
      "Epoch 16 train loss: 0.6153852611275042\n",
      "Epoch 16 val loss: 0.6235735535621643\n",
      "End epoch 16\n",
      "Start epoch 17\n",
      "Epoch 17 train loss: 0.614844896530701\n",
      "Epoch 17 val loss: 0.6208664953708649\n",
      "End epoch 17\n",
      "Start epoch 18\n",
      "Epoch 18 train loss: 0.613103080604036\n",
      "Epoch 18 val loss: 0.6205585777759552\n",
      "End epoch 18\n",
      "Start epoch 19\n",
      "Epoch 19 train loss: 0.6120486582739878\n",
      "Epoch 19 val loss: 0.618525626262029\n",
      "End epoch 19\n",
      "Start epoch 20\n",
      "Epoch 20 train loss: 0.6113769629244077\n",
      "Epoch 20 val loss: 0.6230969130992889\n",
      "End epoch 20\n",
      "Start epoch 21\n",
      "Epoch 21 train loss: 0.6106317740375713\n",
      "Epoch 21 val loss: 0.6179629584153493\n",
      "End epoch 21\n",
      "Start epoch 22\n",
      "Epoch 22 train loss: 0.6094134263062881\n",
      "Epoch 22 val loss: 0.6184508860111236\n",
      "End epoch 22\n",
      "Start epoch 23\n",
      "Epoch 23 train loss: 0.6088177965859235\n",
      "Epoch 23 val loss: 0.6163694540659587\n",
      "End epoch 23\n",
      "Start epoch 24\n",
      "Epoch 24 train loss: 0.6080594214342409\n",
      "Epoch 24 val loss: 0.6178260624408722\n",
      "End epoch 24\n",
      "Start epoch 25\n",
      "Epoch 25 train loss: 0.6071642026052637\n",
      "Epoch 25 val loss: 0.6161686281363169\n",
      "End epoch 25\n",
      "Start epoch 26\n",
      "Epoch 26 train loss: 0.6066637822126938\n",
      "Epoch 26 val loss: 0.6149238089720408\n",
      "End epoch 26\n",
      "Start epoch 27\n",
      "Epoch 27 train loss: 0.6059932279384742\n",
      "Epoch 27 val loss: 0.6146120846271514\n",
      "End epoch 27\n",
      "Start epoch 28\n",
      "Epoch 28 train loss: 0.6056186056743234\n",
      "Epoch 28 val loss: 0.6149441043535868\n",
      "End epoch 28\n",
      "Start epoch 29\n",
      "Epoch 29 train loss: 0.6047572175324973\n",
      "Epoch 29 val loss: 0.6129922290643056\n",
      "End epoch 29\n",
      "Start epoch 30\n",
      "Epoch 30 train loss: 0.6041226366818961\n",
      "Epoch 30 val loss: 0.6158082048098247\n",
      "End epoch 30\n",
      "Start epoch 31\n",
      "Epoch 31 train loss: 0.604155164653972\n",
      "Epoch 31 val loss: 0.6135306815306346\n",
      "End epoch 31\n",
      "Start epoch 32\n",
      "Epoch 32 train loss: 0.6030778278738765\n",
      "Epoch 32 val loss: 0.612606410185496\n",
      "End epoch 32\n",
      "Start epoch 33\n",
      "Epoch 33 train loss: 0.6030061608653957\n",
      "Epoch 33 val loss: 0.6131275256474813\n",
      "End epoch 33\n",
      "Start epoch 34\n",
      "Epoch 34 train loss: 0.6023451170678866\n",
      "Epoch 34 val loss: 0.6129677176475525\n",
      "End epoch 34\n",
      "Start epoch 35\n",
      "Epoch 35 train loss: 0.6018138295513088\n",
      "Epoch 35 val loss: 0.6131903072198231\n",
      "End epoch 35\n",
      "Start epoch 36\n",
      "Epoch 36 train loss: 0.6019414880518186\n",
      "Epoch 36 val loss: 0.6128462612628937\n",
      "End epoch 36\n",
      "Start epoch 37\n",
      "Epoch 37 train loss: 0.6009458106453136\n",
      "Epoch 37 val loss: 0.6116412878036499\n",
      "End epoch 37\n",
      "Start epoch 38\n",
      "Epoch 38 train loss: 0.6007202914205648\n",
      "Epoch 38 val loss: 0.6139181137084961\n",
      "End epoch 38\n",
      "Start epoch 39\n",
      "Epoch 39 train loss: 0.6005984590215198\n",
      "Epoch 39 val loss: 0.6113351245721181\n",
      "End epoch 39\n",
      "Start epoch 40\n",
      "Epoch 40 train loss: 0.6003257339283571\n",
      "Epoch 40 val loss: 0.6130150298277537\n",
      "End epoch 40\n",
      "Start epoch 41\n",
      "Epoch 41 train loss: 0.5996129724938991\n",
      "Epoch 41 val loss: 0.6131384611129761\n",
      "End epoch 41\n",
      "Start epoch 42\n",
      "Epoch 42 train loss: 0.5996362657870277\n",
      "Epoch 42 val loss: 0.6116328358650207\n",
      "End epoch 42\n",
      "Start epoch 43\n",
      "Epoch 43 train loss: 0.5993654354143951\n",
      "Epoch 43 val loss: 0.6097585300604502\n",
      "End epoch 43\n",
      "Start epoch 44\n",
      "Epoch 44 train loss: 0.5990120243217986\n",
      "Epoch 44 val loss: 0.6099135518074036\n",
      "End epoch 44\n",
      "Start epoch 45\n",
      "Epoch 45 train loss: 0.5982833393549515\n",
      "Epoch 45 val loss: 0.6107602854569752\n",
      "End epoch 45\n",
      "Start epoch 46\n",
      "Epoch 46 train loss: 0.5985941083754523\n",
      "Epoch 46 val loss: 0.6111586650212606\n",
      "End epoch 46\n",
      "Start epoch 47\n",
      "Epoch 47 train loss: 0.5983374083446245\n",
      "Epoch 47 val loss: 0.6099300483862559\n",
      "End epoch 47\n",
      "Start epoch 48\n",
      "Epoch 48 train loss: 0.5980193781650672\n",
      "Epoch 48 val loss: 0.6111278931299845\n",
      "End epoch 48\n",
      "Start epoch 49\n",
      "Epoch 49 train loss: 0.598148800558963\n",
      "stop training\n",
      "10 vid_mean\n",
      "101521_J559NC\n",
      "42410 10610\n",
      "Start epoch 0\n",
      "Epoch 0 train loss: 0.7959415111915175\n",
      "Epoch 0 val loss: 0.7341844013759068\n",
      "End epoch 0\n",
      "Start epoch 1\n",
      "Epoch 1 train loss: 0.7431678219013903\n",
      "Epoch 1 val loss: 0.726075971410388\n",
      "End epoch 1\n",
      "Start epoch 2\n",
      "Epoch 2 train loss: 0.7315482910139015\n",
      "Epoch 2 val loss: 0.7195005530402774\n",
      "End epoch 2\n",
      "Start epoch 3\n",
      "Epoch 3 train loss: 0.7237666374947651\n",
      "Epoch 3 val loss: 0.7162285418737502\n",
      "End epoch 3\n",
      "Start epoch 4\n",
      "Epoch 4 train loss: 0.7186724547162113\n",
      "Epoch 4 val loss: 0.7275437116622925\n",
      "End epoch 4\n",
      "Start epoch 5\n",
      "Epoch 5 train loss: 0.7150369545063341\n",
      "Epoch 5 val loss: 0.7116674638929821\n",
      "End epoch 5\n",
      "Start epoch 6\n",
      "Epoch 6 train loss: 0.7118489221636072\n",
      "Epoch 6 val loss: 0.7112021020480565\n",
      "End epoch 6\n",
      "Start epoch 7\n",
      "Epoch 7 train loss: 0.7092074590275087\n",
      "Epoch 7 val loss: 0.7110816339651743\n",
      "End epoch 7\n",
      "Start epoch 8\n",
      "Epoch 8 train loss: 0.707435317427279\n",
      "Epoch 8 val loss: 0.7180673437459129\n",
      "End epoch 8\n",
      "Start epoch 9\n",
      "Epoch 9 train loss: 0.7055035219135055\n",
      "Epoch 9 val loss: 0.7076272056216285\n",
      "End epoch 9\n",
      "Start epoch 10\n",
      "Epoch 10 train loss: 0.703500291310161\n",
      "Epoch 10 val loss: 0.726143805753617\n",
      "End epoch 10\n",
      "Start epoch 11\n",
      "Epoch 11 train loss: 0.702137698610145\n",
      "Epoch 11 val loss: 0.7075632441611517\n",
      "End epoch 11\n",
      "Start epoch 12\n",
      "Epoch 12 train loss: 0.7006711065769196\n",
      "Epoch 12 val loss: 0.7105022853329068\n",
      "End epoch 12\n",
      "Start epoch 13\n",
      "Epoch 13 train loss: 0.6989105139152113\n",
      "Epoch 13 val loss: 0.7057826150031317\n",
      "End epoch 13\n",
      "Start epoch 14\n",
      "Epoch 14 train loss: 0.6978448428303362\n",
      "Epoch 14 val loss: 0.7061211041041783\n",
      "End epoch 14\n",
      "Start epoch 15\n",
      "Epoch 15 train loss: 0.6964733370815415\n",
      "Epoch 15 val loss: 0.7036838829517365\n",
      "End epoch 15\n",
      "Start epoch 16\n",
      "Epoch 16 train loss: 0.6957952365817794\n",
      "Epoch 16 val loss: 0.7051637130124229\n",
      "End epoch 16\n",
      "Start epoch 17\n",
      "Epoch 17 train loss: 0.6944181527718004\n",
      "Epoch 17 val loss: 0.7111842589718955\n",
      "End epoch 17\n",
      "Start epoch 18\n",
      "Epoch 18 train loss: 0.6933259472071406\n",
      "Epoch 18 val loss: 0.7034683199155898\n",
      "End epoch 18\n",
      "Start epoch 19\n",
      "Epoch 19 train loss: 0.6923625164003258\n",
      "Epoch 19 val loss: 0.7036025580905733\n",
      "End epoch 19\n",
      "Start epoch 20\n",
      "Epoch 20 train loss: 0.6913368342870689\n",
      "Epoch 20 val loss: 0.7030631105105082\n",
      "End epoch 20\n",
      "Start epoch 21\n",
      "Epoch 21 train loss: 0.690924334956939\n",
      "Epoch 21 val loss: 0.7038714332239968\n",
      "End epoch 21\n",
      "Start epoch 22\n",
      "Epoch 22 train loss: 0.6897930165371263\n",
      "Epoch 22 val loss: 0.7039131976309276\n",
      "End epoch 22\n",
      "Start epoch 23\n",
      "Epoch 23 train loss: 0.689475947833923\n",
      "Epoch 23 val loss: 0.7069855190458751\n",
      "End epoch 23\n",
      "Start epoch 24\n",
      "Epoch 24 train loss: 0.6886377478220377\n",
      "Epoch 24 val loss: 0.70360191095443\n",
      "End epoch 24\n",
      "Start epoch 25\n",
      "Epoch 25 train loss: 0.6881511082132179\n",
      "Epoch 25 val loss: 0.7015509960197267\n",
      "End epoch 25\n",
      "Start epoch 26\n",
      "Epoch 26 train loss: 0.6880510427865637\n",
      "Epoch 26 val loss: 0.7022802389803386\n",
      "End epoch 26\n",
      "Start epoch 27\n",
      "Epoch 27 train loss: 0.6871699805719307\n",
      "Epoch 27 val loss: 0.702236913499378\n",
      "End epoch 27\n",
      "Start epoch 28\n",
      "Epoch 28 train loss: 0.6865941882133484\n",
      "Epoch 28 val loss: 0.7028647732167017\n",
      "End epoch 28\n",
      "Start epoch 29\n",
      "Epoch 29 train loss: 0.6860902187335922\n",
      "Epoch 29 val loss: 0.7028759703749702\n",
      "End epoch 29\n",
      "Start epoch 30\n",
      "Epoch 30 train loss: 0.6854020802371473\n",
      "Epoch 30 val loss: 0.7016849957761311\n",
      "End epoch 30\n",
      "Start epoch 31\n",
      "Epoch 31 train loss: 0.6850208622145365\n",
      "Epoch 31 val loss: 0.7012020108245668\n",
      "End epoch 31\n",
      "Start epoch 32\n",
      "Epoch 32 train loss: 0.6846533220216452\n",
      "Epoch 32 val loss: 0.7108688425450098\n",
      "End epoch 32\n",
      "Start epoch 33\n",
      "Epoch 33 train loss: 0.684166362845754\n",
      "Epoch 33 val loss: 0.7032700464839027\n",
      "End epoch 33\n",
      "Start epoch 34\n",
      "Epoch 34 train loss: 0.6838778210691658\n",
      "Epoch 34 val loss: 0.7002179636841729\n",
      "End epoch 34\n",
      "Start epoch 35\n",
      "Epoch 35 train loss: 0.6831019840326654\n",
      "Epoch 35 val loss: 0.7035330392065502\n",
      "End epoch 35\n",
      "Start epoch 36\n",
      "Epoch 36 train loss: 0.6831414563110075\n",
      "Epoch 36 val loss: 0.7061896309966132\n",
      "End epoch 36\n",
      "Start epoch 37\n",
      "Epoch 37 train loss: 0.6827878560646471\n",
      "Epoch 37 val loss: 0.7067419446650005\n",
      "End epoch 37\n",
      "Start epoch 38\n",
      "Epoch 38 train loss: 0.6825726405683771\n",
      "Epoch 38 val loss: 0.702068730479195\n",
      "End epoch 38\n",
      "Start epoch 39\n",
      "Epoch 39 train loss: 0.6821790445281799\n",
      "Epoch 39 val loss: 0.7016152427310035\n",
      "End epoch 39\n",
      "Start epoch 40\n",
      "Epoch 40 train loss: 0.6819861524076347\n",
      "stop training\n",
      "10 vid_mean\n",
      "101521_J559NC\n",
      "42410 10610\n",
      "Start epoch 0\n",
      "Epoch 0 train loss: 0.7959962418998581\n",
      "Epoch 0 val loss: 0.7331475700650897\n",
      "End epoch 0\n",
      "Start epoch 1\n",
      "Epoch 1 train loss: 0.7415899555367159\n",
      "Epoch 1 val loss: 0.7237520246278673\n",
      "End epoch 1\n",
      "Start epoch 2\n",
      "Epoch 2 train loss: 0.7297162320240435\n",
      "Epoch 2 val loss: 0.7171257606574467\n",
      "End epoch 2\n",
      "Start epoch 3\n",
      "Epoch 3 train loss: 0.7204655498625284\n",
      "Epoch 3 val loss: 0.7109691812878564\n",
      "End epoch 3\n",
      "Start epoch 4\n",
      "Epoch 4 train loss: 0.7150694781757263\n",
      "Epoch 4 val loss: 0.7150405673753648\n",
      "End epoch 4\n",
      "Start epoch 5\n",
      "Epoch 5 train loss: 0.7104765474796295\n",
      "Epoch 5 val loss: 0.7047085350468045\n",
      "End epoch 5\n",
      "Start epoch 6\n",
      "Epoch 6 train loss: 0.707158154751881\n",
      "Epoch 6 val loss: 0.7045201872076307\n",
      "End epoch 6\n",
      "Start epoch 7\n",
      "Epoch 7 train loss: 0.7050424394119217\n",
      "Epoch 7 val loss: 0.7031253831727164\n",
      "End epoch 7\n",
      "Start epoch 8\n",
      "Epoch 8 train loss: 0.7017975431608866\n",
      "Epoch 8 val loss: 0.704422455458414\n",
      "End epoch 8\n",
      "Start epoch 9\n",
      "Epoch 9 train loss: 0.7001188210694187\n",
      "Epoch 9 val loss: 0.7005583218165806\n",
      "End epoch 9\n",
      "Start epoch 10\n",
      "Epoch 10 train loss: 0.6980532504707934\n",
      "Epoch 10 val loss: 0.7084548075993856\n",
      "End epoch 10\n",
      "Start epoch 11\n",
      "Epoch 11 train loss: 0.6961954573550856\n",
      "Epoch 11 val loss: 0.6990697100048974\n",
      "End epoch 11\n",
      "Start epoch 12\n",
      "Epoch 12 train loss: 0.6943504652345037\n",
      "Epoch 12 val loss: 0.7045337075278872\n",
      "End epoch 12\n",
      "Start epoch 13\n",
      "Epoch 13 train loss: 0.6936812720384943\n",
      "Epoch 13 val loss: 0.6985063155492147\n",
      "End epoch 13\n",
      "Start epoch 14\n",
      "Epoch 14 train loss: 0.6914048737072083\n",
      "Epoch 14 val loss: 0.6976396725291297\n",
      "End epoch 14\n",
      "Start epoch 15\n",
      "Epoch 15 train loss: 0.6902890338237027\n",
      "Epoch 15 val loss: 0.6941768952778408\n",
      "End epoch 15\n",
      "Start epoch 16\n",
      "Epoch 16 train loss: 0.6889922094632344\n",
      "Epoch 16 val loss: 0.6940368499074664\n",
      "End epoch 16\n",
      "Start epoch 17\n",
      "Epoch 17 train loss: 0.6882148525082922\n",
      "Epoch 17 val loss: 0.7066953522818429\n",
      "End epoch 17\n",
      "Start epoch 18\n",
      "Epoch 18 train loss: 0.6867210645991636\n",
      "Epoch 18 val loss: 0.6945267617702484\n",
      "End epoch 18\n",
      "Start epoch 19\n",
      "Epoch 19 train loss: 0.6858176872672805\n",
      "Epoch 19 val loss: 0.6961147998060498\n",
      "End epoch 19\n",
      "Start epoch 20\n",
      "Epoch 20 train loss: 0.6845210930669164\n",
      "Epoch 20 val loss: 0.6921261478038061\n",
      "End epoch 20\n",
      "Start epoch 21\n",
      "Epoch 21 train loss: 0.6840229939265423\n",
      "Epoch 21 val loss: 0.6907794589088077\n",
      "End epoch 21\n",
      "Start epoch 22\n",
      "Epoch 22 train loss: 0.6835834179297987\n",
      "Epoch 22 val loss: 0.6895686842146374\n",
      "End epoch 22\n",
      "Start epoch 23\n",
      "Epoch 23 train loss: 0.6826774671853307\n",
      "Epoch 23 val loss: 0.6916929511796861\n",
      "End epoch 23\n",
      "Start epoch 24\n",
      "Epoch 24 train loss: 0.6813236701201244\n",
      "Epoch 24 val loss: 0.6927789378733862\n",
      "End epoch 24\n",
      "Start epoch 25\n",
      "Epoch 25 train loss: 0.6811660082943468\n",
      "Epoch 25 val loss: 0.6918898295788538\n",
      "End epoch 25\n",
      "Start epoch 26\n",
      "Epoch 26 train loss: 0.680063855576228\n",
      "Epoch 26 val loss: 0.6918284850461143\n",
      "End epoch 26\n",
      "Start epoch 27\n",
      "Epoch 27 train loss: 0.6797233909727579\n",
      "Epoch 27 val loss: 0.6881811703954425\n",
      "End epoch 27\n",
      "Start epoch 28\n",
      "Epoch 28 train loss: 0.6789952186216791\n",
      "Epoch 28 val loss: 0.6878704542205447\n",
      "End epoch 28\n",
      "Start epoch 29\n",
      "Epoch 29 train loss: 0.6790386506591934\n",
      "Epoch 29 val loss: 0.6876728123142606\n",
      "End epoch 29\n",
      "Start epoch 30\n",
      "Epoch 30 train loss: 0.6784284556486521\n",
      "Epoch 30 val loss: 0.6875097240720477\n",
      "End epoch 30\n",
      "Start epoch 31\n",
      "Epoch 31 train loss: 0.6778048582105751\n",
      "Epoch 31 val loss: 0.6888294730867658\n",
      "End epoch 31\n",
      "Start epoch 32\n",
      "Epoch 32 train loss: 0.6774718721947038\n",
      "Epoch 32 val loss: 0.6868115734486353\n",
      "End epoch 32\n",
      "Start epoch 33\n",
      "Epoch 33 train loss: 0.6766728995794273\n",
      "Epoch 33 val loss: 0.6882497881140027\n",
      "End epoch 33\n",
      "Start epoch 34\n",
      "Epoch 34 train loss: 0.6763335394572063\n",
      "Epoch 34 val loss: 0.6884121440705799\n",
      "End epoch 34\n",
      "Start epoch 35\n",
      "Epoch 35 train loss: 0.6754110028226692\n",
      "Epoch 35 val loss: 0.688345805520103\n",
      "End epoch 35\n",
      "Start epoch 36\n",
      "Epoch 36 train loss: 0.6761030633765531\n",
      "Epoch 36 val loss: 0.6924942150002434\n",
      "End epoch 36\n",
      "Start epoch 37\n",
      "Epoch 37 train loss: 0.6753097611019411\n",
      "Epoch 37 val loss: 0.6916866770812443\n",
      "End epoch 37\n",
      "Start epoch 38\n",
      "Epoch 38 train loss: 0.6748367874737246\n",
      "stop training\n",
      "10 vid_mean\n",
      "110421_J569LT\n",
      "32940 8240\n",
      "Start epoch 0\n",
      "Epoch 0 train loss: 0.8175667487373648\n",
      "Epoch 0 val loss: 0.7667052998687282\n",
      "End epoch 0\n",
      "Start epoch 1\n",
      "Epoch 1 train loss: 0.7709782465483791\n",
      "Epoch 1 val loss: 0.7601619128024939\n",
      "End epoch 1\n",
      "Start epoch 2\n",
      "Epoch 2 train loss: 0.7583763068036515\n",
      "Epoch 2 val loss: 0.7568122166575808\n",
      "End epoch 2\n",
      "Start epoch 3\n",
      "Epoch 3 train loss: 0.7498395840326945\n",
      "Epoch 3 val loss: 0.7544008655981584\n",
      "End epoch 3\n",
      "Start epoch 4\n",
      "Epoch 4 train loss: 0.7433163140171258\n",
      "Epoch 4 val loss: 0.7531794797290455\n",
      "End epoch 4\n",
      "Start epoch 5\n",
      "Epoch 5 train loss: 0.738102237845576\n",
      "Epoch 5 val loss: 0.7509112267783193\n",
      "End epoch 5\n",
      "Start epoch 6\n",
      "Epoch 6 train loss: 0.7341927359270495\n",
      "Epoch 6 val loss: 0.7494247555732727\n",
      "End epoch 6\n",
      "Start epoch 7\n",
      "Epoch 7 train loss: 0.7308483973954075\n",
      "Epoch 7 val loss: 0.7537187753301678\n",
      "End epoch 7\n",
      "Start epoch 8\n",
      "Epoch 8 train loss: 0.7278440456057704\n",
      "Epoch 8 val loss: 0.7526172200838724\n",
      "End epoch 8\n",
      "Start epoch 9\n",
      "Epoch 9 train loss: 0.725317588148191\n",
      "Epoch 9 val loss: 0.7517148834286314\n",
      "End epoch 9\n",
      "Start epoch 10\n",
      "Epoch 10 train loss: 0.7226693158925965\n",
      "Epoch 10 val loss: 0.7427260189345388\n",
      "End epoch 10\n",
      "Start epoch 11\n",
      "Epoch 11 train loss: 0.720933433651\n",
      "Epoch 11 val loss: 0.7455172285889134\n",
      "End epoch 11\n",
      "Start epoch 12\n",
      "Epoch 12 train loss: 0.7193594699682191\n",
      "Epoch 12 val loss: 0.7457051927393133\n",
      "End epoch 12\n",
      "Start epoch 13\n",
      "Epoch 13 train loss: 0.717699013477148\n",
      "Epoch 13 val loss: 0.7470438028826858\n",
      "End epoch 13\n",
      "Start epoch 14\n",
      "Epoch 14 train loss: 0.716179023879443\n",
      "Epoch 14 val loss: 0.7541785565289584\n",
      "End epoch 14\n",
      "Start epoch 15\n",
      "Epoch 15 train loss: 0.7145234314046165\n",
      "Epoch 15 val loss: 0.7457521015947516\n",
      "End epoch 15\n",
      "Start epoch 16\n",
      "Epoch 16 train loss: 0.7137117852536283\n",
      "Epoch 16 val loss: 0.7409286336465315\n",
      "End epoch 16\n",
      "Start epoch 17\n",
      "Epoch 17 train loss: 0.7124162482660871\n",
      "Epoch 17 val loss: 0.7444087411418105\n",
      "End epoch 17\n",
      "Start epoch 18\n",
      "Epoch 18 train loss: 0.7114424945772156\n",
      "Epoch 18 val loss: 0.7426844600475195\n",
      "End epoch 18\n",
      "Start epoch 19\n",
      "Epoch 19 train loss: 0.7105452016342518\n",
      "Epoch 19 val loss: 0.7504434242393031\n",
      "End epoch 19\n",
      "Start epoch 20\n",
      "Epoch 20 train loss: 0.7093444249426671\n",
      "Epoch 20 val loss: 0.749406149893096\n",
      "End epoch 20\n",
      "Start epoch 21\n",
      "Epoch 21 train loss: 0.7085436314575432\n",
      "Epoch 21 val loss: 0.7424852522936735\n",
      "End epoch 21\n",
      "Start epoch 22\n",
      "Epoch 22 train loss: 0.7076529407686041\n",
      "stop training\n",
      "10 vid_mean\n",
      "110421_J569LT\n",
      "32940 8240\n",
      "Start epoch 0\n",
      "Epoch 0 train loss: 0.8166485872379569\n",
      "Epoch 0 val loss: 0.7702989957549355\n",
      "End epoch 0\n",
      "Start epoch 1\n",
      "Epoch 1 train loss: 0.7739332480023998\n",
      "Epoch 1 val loss: 0.7638221816583113\n",
      "End epoch 1\n",
      "Start epoch 2\n",
      "Epoch 2 train loss: 0.7620146366976952\n",
      "Epoch 2 val loss: 0.7637298721255679\n",
      "End epoch 2\n",
      "Start epoch 3\n",
      "Epoch 3 train loss: 0.7542966303899307\n",
      "Epoch 3 val loss: 0.7557975559523611\n",
      "End epoch 3\n",
      "Start epoch 4\n",
      "Epoch 4 train loss: 0.7476174244584963\n",
      "Epoch 4 val loss: 0.7555368578795231\n",
      "End epoch 4\n",
      "Start epoch 5\n",
      "Epoch 5 train loss: 0.7418128635532172\n",
      "Epoch 5 val loss: 0.7505192774714846\n",
      "End epoch 5\n",
      "Start epoch 6\n",
      "Epoch 6 train loss: 0.7373970358870751\n",
      "Epoch 6 val loss: 0.7497137206973452\n",
      "End epoch 6\n",
      "Start epoch 7\n",
      "Epoch 7 train loss: 0.7335222303405289\n",
      "Epoch 7 val loss: 0.7443676554795468\n",
      "End epoch 7\n",
      "Start epoch 8\n",
      "Epoch 8 train loss: 0.7307679237321366\n",
      "Epoch 8 val loss: 0.7444719491582928\n",
      "End epoch 8\n",
      "Start epoch 9\n",
      "Epoch 9 train loss: 0.727095177007276\n",
      "Epoch 9 val loss: 0.7444251197757144\n",
      "End epoch 9\n",
      "Start epoch 10\n",
      "Epoch 10 train loss: 0.7249981520711913\n",
      "Epoch 10 val loss: 0.7407112157706058\n",
      "End epoch 10\n",
      "Start epoch 11\n",
      "Epoch 11 train loss: 0.7228865230730338\n",
      "Epoch 11 val loss: 0.7395385088342609\n",
      "End epoch 11\n",
      "Start epoch 12\n",
      "Epoch 12 train loss: 0.720916323883589\n",
      "Epoch 12 val loss: 0.7423771276618495\n",
      "End epoch 12\n",
      "Start epoch 13\n",
      "Epoch 13 train loss: 0.7190344670946284\n",
      "Epoch 13 val loss: 0.7364257230903163\n",
      "End epoch 13\n",
      "Start epoch 14\n",
      "Epoch 14 train loss: 0.7170528727908467\n",
      "Epoch 14 val loss: 0.7352228706533258\n",
      "End epoch 14\n",
      "Start epoch 15\n",
      "Epoch 15 train loss: 0.7157432741897051\n",
      "Epoch 15 val loss: 0.7358075001023032\n",
      "End epoch 15\n",
      "Start epoch 16\n",
      "Epoch 16 train loss: 0.7147145548532176\n",
      "Epoch 16 val loss: 0.7358167460470488\n",
      "End epoch 16\n",
      "Start epoch 17\n",
      "Epoch 17 train loss: 0.7126233402148697\n",
      "Epoch 17 val loss: 0.7319477543686376\n",
      "End epoch 17\n",
      "Start epoch 18\n",
      "Epoch 18 train loss: 0.7117744979932327\n",
      "Epoch 18 val loss: 0.7359123916336985\n",
      "End epoch 18\n",
      "Start epoch 19\n",
      "Epoch 19 train loss: 0.7105173237564028\n",
      "Epoch 19 val loss: 0.7325514554977417\n",
      "End epoch 19\n",
      "Start epoch 20\n",
      "Epoch 20 train loss: 0.7098141617553179\n",
      "Epoch 20 val loss: 0.74147040013111\n",
      "End epoch 20\n",
      "Start epoch 21\n",
      "Epoch 21 train loss: 0.7089063691538434\n",
      "Epoch 21 val loss: 0.7288867831230164\n",
      "End epoch 21\n",
      "Start epoch 22\n",
      "Epoch 22 train loss: 0.7078654544298039\n",
      "Epoch 22 val loss: 0.732401273467324\n",
      "End epoch 22\n",
      "Start epoch 23\n",
      "Epoch 23 train loss: 0.7076813125795172\n",
      "Epoch 23 val loss: 0.7284227429014264\n",
      "End epoch 23\n",
      "Start epoch 24\n",
      "Epoch 24 train loss: 0.7061693571334662\n",
      "Epoch 24 val loss: 0.7267600297927856\n",
      "End epoch 24\n",
      "Start epoch 25\n",
      "Epoch 25 train loss: 0.7051094294518463\n",
      "Epoch 25 val loss: 0.7325604991479353\n",
      "End epoch 25\n",
      "Start epoch 26\n",
      "Epoch 26 train loss: 0.7040523188982823\n",
      "Epoch 26 val loss: 0.7316449591607759\n",
      "End epoch 26\n",
      "Start epoch 27\n",
      "Epoch 27 train loss: 0.7033408413561739\n",
      "Epoch 27 val loss: 0.733121779831973\n",
      "End epoch 27\n",
      "Start epoch 28\n",
      "Epoch 28 train loss: 0.7033793949341589\n",
      "Epoch 28 val loss: 0.7388741626883998\n",
      "End epoch 28\n",
      "Start epoch 29\n",
      "Epoch 29 train loss: 0.7023794554000677\n",
      "Epoch 29 val loss: 0.7294896190816705\n",
      "End epoch 29\n",
      "Start epoch 30\n",
      "Epoch 30 train loss: 0.7017363674880922\n",
      "stop training\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for segment_num in [10]:\n",
    "\n",
    "    for file_id, num_neurons in [(\"070921_J553RT\", 68), (\"101521_J559NC\", 49), (\"110421_J569LT\", 32)]:\n",
    "        for shifter in [False, True]:\n",
    "\n",
    "            for vid_type in [\"vid_mean\"]:\n",
    "    \n",
    "                print(segment_num, vid_type)\n",
    "                print(file_id)\n",
    "    \n",
    "                model = Predictor(num_neurons=num_neurons).to(device)\n",
    "                args.file_id = file_id\n",
    "                args.num_neurons = num_neurons\n",
    "                args.shifter = shifter\n",
    "                \n",
    "                args.segment_num = segment_num\n",
    "                args.vid_type = vid_type\n",
    "                args.best_train_path = \"/hdd/yuchen/trainCNNshifter{}_{}_{}_{}.pth\".format(shifter, segment_num, vid_type, file_id)\n",
    "                args.best_val_path = \"/home/yuchen/valCNNshifter{}_{}_{}_{}.pth\".format(shifter, segment_num, vid_type, file_id)\n",
    "    \n",
    "                train_loss_list, val_loss_list = train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default is smoothing with 2 second, 48 ms per frame\n",
    "def smoothing_with_np_conv(nsp, size=int(2000/48)):\n",
    "    np_conv_res = []\n",
    "    for i in range(nsp.shape[1]):\n",
    "        np_conv_res.append(np.convolve(nsp[:, i], np.ones(size)/size, mode=\"same\"))        \n",
    "    np_conv_res = np.transpose(np.array(np_conv_res))\n",
    "    return np_conv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, weights_path, dataset, device):\n",
    "\n",
    "    dl = DataLoader(dataset=dataset, batch_size=256, shuffle=False, num_workers=4)\n",
    "    \n",
    "    model.load_state_dict(torch.load(weights_path))\n",
    "\n",
    "    ground_truth_all = []\n",
    "    pred_all = []\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():      \n",
    "        \n",
    "        for (image, behav, spikes) in dl:\n",
    "            \n",
    "            image = image.to(device)\n",
    "            behav = behav.to(device)\n",
    "            image = torch.squeeze(image, axis=1)\n",
    "            \n",
    "            pred = model(image, behav)\n",
    "            \n",
    "            ground_truth_all.append(spikes.numpy())\n",
    "            pred_all.append(pred.cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(pred_all, axis=0), np.concatenate(ground_truth_all, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 vid_mean\n",
      "070921_J553RT\n",
      "False\n",
      "30120 7540\n",
      "R2 0.793610\n",
      "MSE 0.069301\n",
      "mean corr, 0.548+-0.148\n",
      "max corr 0.818012\n",
      "min corr 0.113838\n",
      "10 vid_mean\n",
      "070921_J553RT\n",
      "True\n",
      "30120 7540\n",
      "R2 0.818868\n",
      "MSE 0.062573\n",
      "mean corr, 0.596+-0.134\n",
      "max corr 0.835106\n",
      "min corr 0.251532\n",
      "10 vid_mean\n",
      "101521_J559NC\n",
      "False\n",
      "42410 10610\n",
      "R2 0.747371\n",
      "MSE 0.094048\n",
      "mean corr, 0.501+-0.146\n",
      "max corr 0.782938\n",
      "min corr 0.180965\n",
      "10 vid_mean\n",
      "101521_J559NC\n",
      "True\n",
      "42410 10610\n",
      "R2 0.748561\n",
      "MSE 0.090836\n",
      "mean corr, 0.552+-0.138\n",
      "max corr 0.816897\n",
      "min corr 0.252751\n",
      "10 vid_mean\n",
      "110421_J569LT\n",
      "False\n",
      "32940 8240\n",
      "R2 0.353561\n",
      "MSE 0.102223\n",
      "mean corr, 0.398+-0.170\n",
      "max corr 0.714962\n",
      "min corr 0.092378\n",
      "10 vid_mean\n",
      "110421_J569LT\n",
      "True\n",
      "32940 8240\n",
      "R2 0.327394\n",
      "MSE 0.100088\n",
      "mean corr, 0.424+-0.141\n",
      "max corr 0.736949\n",
      "min corr 0.181917\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  r2_score, mean_squared_error\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for segment_num in [10]:\n",
    "\n",
    "    for file_id, num_neurons in [(\"070921_J553RT\", 68), (\"101521_J559NC\", 49), (\"110421_J569LT\", 32)]:\n",
    "\n",
    "        for vid_type in [\"vid_mean\"]:\n",
    "            for shifter in [False, True]:\n",
    "                print(segment_num, vid_type)\n",
    "                print(file_id)\n",
    "                print(shifter)\n",
    "                args.file_id = file_id\n",
    "                args.num_neurons = num_neurons\n",
    "                args.segment_num = segment_num\n",
    "                args.vid_type = vid_type\n",
    "                args.shifter=shifter\n",
    "                args.best_train_path = \"/hdd/yuchen/trainCNNshifter{}_{}_{}_{}.pth\".format(args.shifter, segment_num, vid_type, file_id)\n",
    "                args.best_val_path = \"/home/yuchen/valCNNshifter{}_{}_{}_{}.pth\".format(args.shifter, segment_num, vid_type, file_id)\n",
    "                model = Predictor(num_neurons=num_neurons).to(device)\n",
    "                \n",
    "        \n",
    "                train_ds, val_ds = load_train_val_ds()\n",
    "                test_ds = load_test_ds()\n",
    "    \n",
    "                pred, label = evaluate_model(model, weights_path=args.best_val_path, dataset=test_ds, device=device)\n",
    "                cor_array = cor_in_time(pred, label)\n",
    "            #     print(\"best val model on test dataset, {:.3f}+-{:.3f}\".format(np.mean(cor_array), np.std(cor_array)))\n",
    "                pred = smoothing_with_np_conv(pred)\n",
    "                label = smoothing_with_np_conv(label)\n",
    "                print(\"R2\", \"{:.6f}\".format(r2_score(label.T, pred.T)))\n",
    "                print(\"MSE\", \"{:.6f}\".format(mean_squared_error(label, pred)))\n",
    "                cor_array = cor_in_time(pred, label)\n",
    "                print(\"mean corr, {:.3f}+-{:.3f}\".format(np.mean(cor_array), np.std(cor_array)))\n",
    "                print(\"max corr\", \"{:.6f}\".format(np.max(cor_array)))\n",
    "                print(\"min corr\", \"{:.6f}\".format(np.min(cor_array)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save per neuron correlation for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 vid_mean\n",
      "070921_J553RT\n",
      "False\n",
      "30120 7540\n",
      "R2 0.793610\n",
      "MSE 0.069301\n",
      "mean corr, 0.548+-0.148\n",
      "max corr 0.818012\n",
      "min corr 0.113838\n",
      "10 vid_mean\n",
      "070921_J553RT\n",
      "True\n",
      "30120 7540\n",
      "R2 0.818868\n",
      "MSE 0.062573\n",
      "mean corr, 0.596+-0.134\n",
      "max corr 0.835106\n",
      "min corr 0.251532\n",
      "10 vid_mean\n",
      "101521_J559NC\n",
      "False\n",
      "42410 10610\n",
      "R2 0.747371\n",
      "MSE 0.094048\n",
      "mean corr, 0.501+-0.146\n",
      "max corr 0.782938\n",
      "min corr 0.180965\n",
      "10 vid_mean\n",
      "101521_J559NC\n",
      "True\n",
      "42410 10610\n",
      "R2 0.748561\n",
      "MSE 0.090836\n",
      "mean corr, 0.552+-0.138\n",
      "max corr 0.816897\n",
      "min corr 0.252751\n",
      "10 vid_mean\n",
      "110421_J569LT\n",
      "False\n",
      "32940 8240\n",
      "R2 0.353561\n",
      "MSE 0.102223\n",
      "mean corr, 0.398+-0.170\n",
      "max corr 0.714962\n",
      "min corr 0.092378\n",
      "10 vid_mean\n",
      "110421_J569LT\n",
      "True\n",
      "32940 8240\n",
      "R2 0.327394\n",
      "MSE 0.100088\n",
      "mean corr, 0.424+-0.141\n",
      "max corr 0.736949\n",
      "min corr 0.181917\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "for segment_num in [10]:\n",
    "\n",
    "    for file_id, num_neurons in [(\"070921_J553RT\", 68), (\"101521_J559NC\", 49), (\"110421_J569LT\", 32)]:\n",
    "\n",
    "        for vid_type in [\"vid_mean\"]:\n",
    "            for shifter in [False, True]:\n",
    "                print(segment_num, vid_type)\n",
    "                print(file_id)\n",
    "                print(shifter)\n",
    "                args.file_id = file_id\n",
    "                args.num_neurons = num_neurons\n",
    "                args.segment_num = segment_num\n",
    "                args.vid_type = vid_type\n",
    "                args.shifter=shifter\n",
    "                args.best_train_path = \"/hdd/yuchen/trainCNNshifter{}_{}_{}_{}.pth\".format(args.shifter, segment_num, vid_type, file_id)\n",
    "                args.best_val_path = \"/home/yuchen/valCNNshifter{}_{}_{}_{}.pth\".format(args.shifter, segment_num, vid_type, file_id)\n",
    "                model = Predictor(num_neurons=num_neurons).to(device)\n",
    "                \n",
    "        \n",
    "                train_ds, val_ds = load_train_val_ds()\n",
    "                test_ds = load_test_ds()\n",
    "    \n",
    "                pred, label = evaluate_model(model, weights_path=args.best_val_path, dataset=test_ds, device=device)\n",
    "                cor_array = cor_in_time(pred, label)\n",
    "            #     print(\"best val model on test dataset, {:.3f}+-{:.3f}\".format(np.mean(cor_array), np.std(cor_array)))\n",
    "                pred = smoothing_with_np_conv(pred)\n",
    "                label = smoothing_with_np_conv(label)\n",
    "                print(\"R2\", \"{:.6f}\".format(r2_score(label.T, pred.T)))\n",
    "                print(\"MSE\", \"{:.6f}\".format(mean_squared_error(label, pred)))\n",
    "                cor_array = cor_in_time(pred, label)\n",
    "                np.save(\"corr_cnn_shifter/{}_shifter_{}_seq_1.npy\".format(file_id, shifter), cor_array)\n",
    "                print(\"mean corr, {:.3f}+-{:.3f}\".format(np.mean(cor_array), np.std(cor_array)))\n",
    "                print(\"max corr\", \"{:.6f}\".format(np.max(cor_array)))\n",
    "                print(\"min corr\", \"{:.6f}\".format(np.min(cor_array)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
